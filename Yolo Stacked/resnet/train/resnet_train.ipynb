{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49576916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x2a7670e17f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46bd5af",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac72c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file dataset already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir dataset\n",
    "!tar -xf ssbi-dataset-v1.0.0.zip -C dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87adee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_path = \"dataset/annotations/instances_train.json\"\n",
    "val_json_path = \"dataset/annotations/instances_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee9bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a path to a coco json return a df containing filename, category_id, bounding box \n",
    "def coco_to_df(path):\n",
    "    with open(path) as f:\n",
    "        j = json.load(f)\n",
    "\n",
    "    #put annotations and images into their own dataframs \n",
    "    annotations = pd.DataFrame(j['annotations'])\n",
    "    images = pd.DataFrame(j['images'])\n",
    "\n",
    "    #merge the two to get all important info and filter for only categories 6 or 7 forged or genuine \n",
    "    df1 = annotations[[\"image_id\", \"category_id\", \"bbox\"]]\n",
    "    df2 = images[[\"id\", \"file_name\"]]\n",
    "    df2 = df2.rename(columns={\"id\": \"image_id\"})\n",
    "    final = df1.merge(df2, on='image_id')\n",
    "\n",
    "    final = final[final['category_id'].isin([6, 7])].reset_index(drop=True)\n",
    "    final['category_id'] = final['category_id'].replace(6, 1)\n",
    "    final['category_id'] = final['category_id'].replace(7, 0)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75feb813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[2574, 856, 284, 307]</td>\n",
       "      <td>check_009_001_F1_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[1671, 599, 166, 180]</td>\n",
       "      <td>check_008_001_F1_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[746, 262, 98, 106]</td>\n",
       "      <td>check_007_001_F1_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[655, 239, 92, 85]</td>\n",
       "      <td>check_004_001_F1_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[717, 262, 114, 106]</td>\n",
       "      <td>check_007_001_F1_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>4352</td>\n",
       "      <td>0</td>\n",
       "      <td>[818, 331, 109, 70]</td>\n",
       "      <td>check_012_019_G3_6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>4353</td>\n",
       "      <td>0</td>\n",
       "      <td>[1036, 417, 149, 96]</td>\n",
       "      <td>check_016_019_G3_6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>4355</td>\n",
       "      <td>0</td>\n",
       "      <td>[720, 242, 148, 95]</td>\n",
       "      <td>check_020_019_G3_6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>4357</td>\n",
       "      <td>0</td>\n",
       "      <td>[872, 261, 93, 70]</td>\n",
       "      <td>check_017_019_G3_7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>4358</td>\n",
       "      <td>0</td>\n",
       "      <td>[651, 235, 84, 63]</td>\n",
       "      <td>check_011_019_G3_7.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3052 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id  category_id                   bbox               file_name\n",
       "0            1            1  [2574, 856, 284, 307]  check_009_001_F1_0.jpg\n",
       "1            2            1  [1671, 599, 166, 180]  check_008_001_F1_0.jpg\n",
       "2            5            1    [746, 262, 98, 106]  check_007_001_F1_0.jpg\n",
       "3            7            1     [655, 239, 92, 85]  check_004_001_F1_1.jpg\n",
       "4            9            1   [717, 262, 114, 106]  check_007_001_F1_1.jpg\n",
       "...        ...          ...                    ...                     ...\n",
       "3047      4352            0    [818, 331, 109, 70]  check_012_019_G3_6.jpg\n",
       "3048      4353            0   [1036, 417, 149, 96]  check_016_019_G3_6.jpg\n",
       "3049      4355            0    [720, 242, 148, 95]  check_020_019_G3_6.jpg\n",
       "3050      4357            0     [872, 261, 93, 70]  check_017_019_G3_7.jpg\n",
       "3051      4358            0     [651, 235, 84, 63]  check_011_019_G3_7.jpg\n",
       "\n",
       "[3052 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[1592, 410, 165, 179]</td>\n",
       "      <td>check_001_001_F1_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[1212, 493, 174, 188]</td>\n",
       "      <td>check_002_001_F1_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[1857, 553, 224, 207]</td>\n",
       "      <td>check_010_001_F1_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>[933, 493, 203, 188]</td>\n",
       "      <td>check_002_001_F1_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[1141, 563, 194, 180]</td>\n",
       "      <td>check_005_001_F1_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>4349</td>\n",
       "      <td>0</td>\n",
       "      <td>[698, 294, 55, 39]</td>\n",
       "      <td>check_019_019_G3_5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>4353</td>\n",
       "      <td>0</td>\n",
       "      <td>[547, 244, 95, 61]</td>\n",
       "      <td>check_018_019_G3_6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>4355</td>\n",
       "      <td>0</td>\n",
       "      <td>[696, 242, 126, 95]</td>\n",
       "      <td>check_020_019_G3_7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>4358</td>\n",
       "      <td>0</td>\n",
       "      <td>[747, 331, 93, 70]</td>\n",
       "      <td>check_012_019_G3_7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>4359</td>\n",
       "      <td>0</td>\n",
       "      <td>[743, 294, 52, 39]</td>\n",
       "      <td>check_019_019_G3_7.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1308 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id  category_id                   bbox               file_name\n",
       "0            3            1  [1592, 410, 165, 179]  check_001_001_F1_0.jpg\n",
       "1            4            1  [1212, 493, 174, 188]  check_002_001_F1_0.jpg\n",
       "2            6            1  [1857, 553, 224, 207]  check_010_001_F1_1.jpg\n",
       "3            8            1   [933, 493, 203, 188]  check_002_001_F1_1.jpg\n",
       "4           10            1  [1141, 563, 194, 180]  check_005_001_F1_1.jpg\n",
       "...        ...          ...                    ...                     ...\n",
       "1303      4349            0     [698, 294, 55, 39]  check_019_019_G3_5.jpg\n",
       "1304      4353            0     [547, 244, 95, 61]  check_018_019_G3_6.jpg\n",
       "1305      4355            0    [696, 242, 126, 95]  check_020_019_G3_7.jpg\n",
       "1306      4358            0     [747, 331, 93, 70]  check_012_019_G3_7.jpg\n",
       "1307      4359            0     [743, 294, 52, 39]  check_019_019_G3_7.jpg\n",
       "\n",
       "[1308 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3052"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = coco_to_df(train_json_path)\n",
    "val_df = coco_to_df(val_json_path)\n",
    "\n",
    "display(train_df)\n",
    "display(val_df)\n",
    "display(len(train_df))\n",
    "display(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd936c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in a dataframe of image and will crop and send back image with id (tensor, id)\n",
    "class SSBI_Dataset(Dataset):\n",
    "    def __init__(self, df, path, transform=None):\n",
    "        self.df = df\n",
    "        self.path = path \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        image = Image.open(os.path.join(self.path, row[\"file_name\"])).convert(\"RGB\")\n",
    "\n",
    "        #crop based on bounding box\n",
    "        x, y, w, h = row['bbox']\n",
    "        image = image.crop([x, y, x+w, y+h])\n",
    "\n",
    "        label = int(row[\"category_id\"])\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed169c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e36cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SSBI_Dataset(train_df, \"dataset/train\", train_transform)\n",
    "val_dataset = SSBI_Dataset(val_df, \"dataset/val\", val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e34e3d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3052\n",
      "1308\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1895ac3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0844, 1.0502, 0.9646,  ..., 0.8789, 0.8789, 0.8789],\n",
      "         [1.0844, 1.0502, 0.9646,  ..., 0.8789, 0.8789, 0.8789],\n",
      "         [1.1015, 1.0673, 0.9817,  ..., 0.8789, 0.8789, 0.8789],\n",
      "         ...,\n",
      "         [0.9132, 0.9132, 0.8961,  ..., 0.6734, 0.6906, 0.7077],\n",
      "         [0.9132, 0.9132, 0.8961,  ..., 0.8618, 0.8789, 0.8961],\n",
      "         [0.9132, 0.9132, 0.8961,  ..., 0.9132, 0.9303, 0.9474]],\n",
      "\n",
      "        [[1.1155, 1.1155, 1.1331,  ..., 1.1506, 1.1506, 1.1506],\n",
      "         [1.1155, 1.1155, 1.1331,  ..., 1.1506, 1.1506, 1.1506],\n",
      "         [1.1155, 1.1155, 1.1331,  ..., 1.1506, 1.1506, 1.1506],\n",
      "         ...,\n",
      "         [1.1856, 1.1856, 1.2031,  ..., 0.9755, 1.0105, 1.0105],\n",
      "         [1.1856, 1.1856, 1.1856,  ..., 1.1331, 1.1681, 1.1856],\n",
      "         [1.1856, 1.1856, 1.1856,  ..., 1.1856, 1.2206, 1.2381]],\n",
      "\n",
      "        [[2.1694, 2.1868, 2.2391,  ..., 2.3088, 2.3088, 2.3088],\n",
      "         [2.1694, 2.1868, 2.2391,  ..., 2.3088, 2.3088, 2.3088],\n",
      "         [2.1868, 2.2043, 2.2566,  ..., 2.3088, 2.3088, 2.3088],\n",
      "         ...,\n",
      "         [2.3437, 2.3437, 2.3437,  ..., 2.0997, 2.1346, 2.1346],\n",
      "         [2.3437, 2.3437, 2.3611,  ..., 2.2566, 2.2740, 2.2740],\n",
      "         [2.3437, 2.3437, 2.3611,  ..., 2.3088, 2.3263, 2.3263]]]) 1\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "print(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e2f706",
   "metadata": {},
   "source": [
    "## Train ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cf7ac91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "dataloaders = {'train' : torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0), \n",
    "               'val' : torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=0)}\n",
    "\n",
    "dataset_sizes = {'train' : len(train_dataset), 'val' : len(val_dataset)}\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ebc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pytorch documentation\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882127e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pytorch documentation\n",
    "def train_model(model, criterion, optimizer, scheduler, patience=7, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_val_loss = float('inf') \n",
    "    patience_counter = 0 \n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        stop_training_flag = False\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                if phase == 'val':\n",
    "                    \n",
    "                    if epoch_acc > best_acc:\n",
    "                        best_acc = epoch_acc\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "                        \n",
    "                    if epoch_loss < best_val_loss:\n",
    "                        best_val_loss = epoch_loss\n",
    "                        patience_counter = 0 \n",
    "                    else:\n",
    "                        patience_counter += 1 \n",
    "\n",
    "                    if patience_counter >= patience:\n",
    "                        print('\\n' + '='*20)\n",
    "                        print(f'EARLY STOPPING: Validation loss did not improve for {patience} epochs.')\n",
    "                        print(f'Stopping at epoch {epoch}.')\n",
    "                        print('='*20)\n",
    "                        stop_training_flag = True\n",
    "                        break \n",
    "\n",
    "            print()\n",
    "            if stop_training_flag:\n",
    "                break\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcded4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714da3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.7051 Acc: 0.7018\n",
      "val Loss: 0.5786 Acc: 0.7630\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.7286 Acc: 0.7038\n",
      "val Loss: 0.5680 Acc: 0.7424\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.6695 Acc: 0.7163\n",
      "val Loss: 0.6040 Acc: 0.7676\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.6516 Acc: 0.7231\n",
      "val Loss: 0.5318 Acc: 0.7584\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.6459 Acc: 0.7225\n",
      "val Loss: 0.5590 Acc: 0.7538\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.6420 Acc: 0.7251\n",
      "val Loss: 0.6820 Acc: 0.7699\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.7287\n",
      "val Loss: 0.5457 Acc: 0.7309\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.5286 Acc: 0.7513\n",
      "val Loss: 0.5216 Acc: 0.7813\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.5200 Acc: 0.7664\n",
      "val Loss: 0.5103 Acc: 0.7546\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.5083 Acc: 0.7631\n",
      "val Loss: 0.5488 Acc: 0.7775\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.5053 Acc: 0.7638\n",
      "val Loss: 0.4986 Acc: 0.7806\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.5006 Acc: 0.7723\n",
      "val Loss: 0.4747 Acc: 0.7829\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.5140 Acc: 0.7651\n",
      "val Loss: 0.4787 Acc: 0.7859\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.4936 Acc: 0.7756\n",
      "val Loss: 0.4728 Acc: 0.7875\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.4934 Acc: 0.7641\n",
      "val Loss: 0.4680 Acc: 0.7905\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.4799 Acc: 0.7818\n",
      "val Loss: 0.4720 Acc: 0.7852\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.4881 Acc: 0.7687\n",
      "val Loss: 0.4772 Acc: 0.7798\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.5058 Acc: 0.7733\n",
      "val Loss: 0.4628 Acc: 0.7898\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.4990 Acc: 0.7723\n",
      "val Loss: 0.4773 Acc: 0.7844\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.4880 Acc: 0.7765\n",
      "val Loss: 0.4766 Acc: 0.7890\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.4978 Acc: 0.7680\n",
      "val Loss: 0.4750 Acc: 0.7882\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.4891 Acc: 0.7769\n",
      "val Loss: 0.4686 Acc: 0.7959\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.4840 Acc: 0.7788\n",
      "val Loss: 0.4802 Acc: 0.7852\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.5029 Acc: 0.7700\n",
      "val Loss: 0.4588 Acc: 0.7913\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.4882 Acc: 0.7762\n",
      "val Loss: 0.4758 Acc: 0.7890\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.4906 Acc: 0.7756\n",
      "val Loss: 0.4781 Acc: 0.7920\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.5016 Acc: 0.7638\n",
      "val Loss: 0.4730 Acc: 0.7821\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.4810 Acc: 0.7828\n",
      "val Loss: 0.4780 Acc: 0.7928\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.4875 Acc: 0.7716\n",
      "val Loss: 0.4710 Acc: 0.7875\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.4936 Acc: 0.7775\n",
      "val Loss: 0.4767 Acc: 0.7836\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.4888 Acc: 0.7818\n",
      "val Loss: 0.4749 Acc: 0.7798\n",
      "\n",
      "====================\n",
      "EARLY STOPPING: Validation loss did not improve for 7 epochs.\n",
      "Stopping at epoch 30.\n",
      "====================\n",
      "\n",
      "Training complete in 26m 42s\n",
      "Best val Acc: 0.795872\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=50)\n",
    "torch.save(model_conv.state_dict(), 'resnet_best_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec6eb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_path = 'resnet_best_weights.pth'\n",
    "\n",
    "model_conv = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "loaded_model = torch.load(best_weights_path, map_location=device, weights_only=False)\n",
    "model_conv.load_state_dict(loaded_model.state_dict(), strict=False)\n",
    "\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model_conv.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#layer4 and last layer\n",
    "optimizer_conv = optim.SGD(\n",
    "    [\n",
    "        {'params': model_conv.fc.parameters(), 'lr': 0.001},  \n",
    "        \n",
    "        {'params': model_conv.layer4.parameters(), 'lr': 0.0001} \n",
    "    ], \n",
    "    momentum=0.9\n",
    ")\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5557decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.4997 Acc: 0.7720\n",
      "val Loss: 0.4503 Acc: 0.8028\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.4869 Acc: 0.7792\n",
      "val Loss: 0.4223 Acc: 0.8180\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.4581 Acc: 0.7939\n",
      "val Loss: 0.3861 Acc: 0.8303\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.4503 Acc: 0.8031\n",
      "val Loss: 0.3751 Acc: 0.8379\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.4426 Acc: 0.8044\n",
      "val Loss: 0.3593 Acc: 0.8479\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.4405 Acc: 0.8021\n",
      "val Loss: 0.3466 Acc: 0.8517\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.4285 Acc: 0.8087\n",
      "val Loss: 0.3294 Acc: 0.8624\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.4040 Acc: 0.8244\n",
      "val Loss: 0.3155 Acc: 0.8662\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.4125 Acc: 0.8142\n",
      "val Loss: 0.3338 Acc: 0.8700\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.4103 Acc: 0.8237\n",
      "val Loss: 0.3204 Acc: 0.8723\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.4126 Acc: 0.8221\n",
      "val Loss: 0.3287 Acc: 0.8593\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.4034 Acc: 0.8254\n",
      "val Loss: 0.3293 Acc: 0.8677\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.4052 Acc: 0.8204\n",
      "val Loss: 0.3173 Acc: 0.8731\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.3990 Acc: 0.8286\n",
      "val Loss: 0.3170 Acc: 0.8662\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.4084 Acc: 0.8231\n",
      "val Loss: 0.3063 Acc: 0.8708\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.3974 Acc: 0.8175\n",
      "val Loss: 0.3219 Acc: 0.8593\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.4102 Acc: 0.8237\n",
      "val Loss: 0.3164 Acc: 0.8685\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.4149 Acc: 0.8237\n",
      "val Loss: 0.3184 Acc: 0.8754\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.4000 Acc: 0.8234\n",
      "val Loss: 0.3131 Acc: 0.8654\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.3954 Acc: 0.8326\n",
      "val Loss: 0.3272 Acc: 0.8616\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.4149 Acc: 0.8201\n",
      "val Loss: 0.2997 Acc: 0.8800\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.3985 Acc: 0.8329\n",
      "val Loss: 0.3114 Acc: 0.8723\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.4057 Acc: 0.8204\n",
      "val Loss: 0.3009 Acc: 0.8739\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.4119 Acc: 0.8178\n",
      "val Loss: 0.3008 Acc: 0.8807\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.4053 Acc: 0.8175\n",
      "val Loss: 0.3104 Acc: 0.8693\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.4081 Acc: 0.8260\n",
      "val Loss: 0.3244 Acc: 0.8723\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.4073 Acc: 0.8218\n",
      "val Loss: 0.3108 Acc: 0.8716\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.4013 Acc: 0.8214\n",
      "val Loss: 0.3000 Acc: 0.8746\n",
      "\n",
      "====================\n",
      "EARLY STOPPING: Validation loss did not improve for 7 epochs.\n",
      "Stopping at epoch 27.\n",
      "====================\n",
      "\n",
      "Training complete in 25m 8s\n",
      "Best val Acc: 0.880734\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=100)\n",
    "torch.save(model_conv.state_dict(), 'resnet_best_weights_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3f6456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_path = 'resnet_best_weights_2.pth'\n",
    "\n",
    "model_conv = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv.load_state_dict(torch.load(best_weights_path, map_location=device, weights_only=False), strict=False)\n",
    "\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model_conv.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model_conv.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#layer4 and last layer\n",
    "optimizer_conv = optim.SGD(\n",
    "    [\n",
    "        {'params': model_conv.fc.parameters(), 'lr': 0.001},  \n",
    "        \n",
    "        {'params': model_conv.layer4.parameters(), 'lr': 0.0001},\n",
    "\n",
    "        {'params': model_conv.layer3.parameters(), 'lr': 0.00001}\n",
    "    ], \n",
    "    momentum=0.9\n",
    ")\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0921dabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.4113 Acc: 0.8234\n",
      "val Loss: 0.2943 Acc: 0.8777\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.3890 Acc: 0.8290\n",
      "val Loss: 0.2826 Acc: 0.8853\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.3927 Acc: 0.8303\n",
      "val Loss: 0.2725 Acc: 0.8907\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.3978 Acc: 0.8290\n",
      "val Loss: 0.2745 Acc: 0.8937\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.3795 Acc: 0.8421\n",
      "val Loss: 0.2528 Acc: 0.9037\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.3746 Acc: 0.8375\n",
      "val Loss: 0.2595 Acc: 0.9014\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.3663 Acc: 0.8463\n",
      "val Loss: 0.2349 Acc: 0.9098\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.3497 Acc: 0.8624\n",
      "val Loss: 0.2295 Acc: 0.9121\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.3565 Acc: 0.8545\n",
      "val Loss: 0.2419 Acc: 0.9044\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.3576 Acc: 0.8503\n",
      "val Loss: 0.2494 Acc: 0.9052\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.3579 Acc: 0.8483\n",
      "val Loss: 0.2335 Acc: 0.9136\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.3520 Acc: 0.8496\n",
      "val Loss: 0.2419 Acc: 0.9067\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.3576 Acc: 0.8529\n",
      "val Loss: 0.2224 Acc: 0.9167\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.3423 Acc: 0.8617\n",
      "val Loss: 0.2108 Acc: 0.9258\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.3586 Acc: 0.8506\n",
      "val Loss: 0.2434 Acc: 0.9037\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.3501 Acc: 0.8493\n",
      "val Loss: 0.2324 Acc: 0.9159\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.3462 Acc: 0.8552\n",
      "val Loss: 0.2402 Acc: 0.9083\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.3557 Acc: 0.8470\n",
      "val Loss: 0.2582 Acc: 0.8945\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.3634 Acc: 0.8483\n",
      "val Loss: 0.2144 Acc: 0.9182\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.3424 Acc: 0.8535\n",
      "val Loss: 0.2286 Acc: 0.9144\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.3554 Acc: 0.8542\n",
      "val Loss: 0.2429 Acc: 0.8937\n",
      "\n",
      "====================\n",
      "EARLY STOPPING: Validation loss did not improve for 7 epochs.\n",
      "Stopping at epoch 20.\n",
      "====================\n",
      "\n",
      "Training complete in 18m 9s\n",
      "Best val Acc: 0.925841\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=100)\n",
    "torch.save(model_conv.state_dict(), 'resnet_best_weights_3.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab614fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c62537f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_path = 'resnet_best_weights_3.pth'\n",
    "\n",
    "model_conv = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv.load_state_dict(torch.load(best_weights_path, map_location=device, weights_only=False), strict=False)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_conv = optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce59fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/149\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 0.7382\n",
      "val Loss: 0.7133 Acc: 0.6919\n",
      "\n",
      "Epoch 1/149\n",
      "----------\n",
      "train Loss: 0.5502 Acc: 0.7782\n",
      "val Loss: 0.3044 Acc: 0.8670\n",
      "\n",
      "Epoch 2/149\n",
      "----------\n",
      "train Loss: 0.4963 Acc: 0.8077\n",
      "val Loss: 0.2006 Acc: 0.9067\n",
      "\n",
      "Epoch 3/149\n",
      "----------\n",
      "train Loss: 0.3995 Acc: 0.8365\n",
      "val Loss: 0.2733 Acc: 0.9434\n",
      "\n",
      "Epoch 4/149\n",
      "----------\n",
      "train Loss: 0.3809 Acc: 0.8453\n",
      "val Loss: 0.1214 Acc: 0.9526\n",
      "\n",
      "Epoch 5/149\n",
      "----------\n",
      "train Loss: 0.3345 Acc: 0.8699\n",
      "val Loss: 0.0663 Acc: 0.9763\n",
      "\n",
      "Epoch 6/149\n",
      "----------\n",
      "train Loss: 0.3106 Acc: 0.8784\n",
      "val Loss: 0.0534 Acc: 0.9763\n",
      "\n",
      "Epoch 7/149\n",
      "----------\n",
      "train Loss: 0.2962 Acc: 0.8788\n",
      "val Loss: 0.0590 Acc: 0.9855\n",
      "\n",
      "Epoch 8/149\n",
      "----------\n",
      "train Loss: 0.2945 Acc: 0.8896\n",
      "val Loss: 0.0418 Acc: 0.9893\n",
      "\n",
      "Epoch 9/149\n",
      "----------\n",
      "train Loss: 0.2821 Acc: 0.8988\n",
      "val Loss: 0.0497 Acc: 0.9847\n",
      "\n",
      "Epoch 10/149\n",
      "----------\n",
      "train Loss: 0.2279 Acc: 0.9220\n",
      "val Loss: 0.0342 Acc: 0.9901\n",
      "\n",
      "Epoch 11/149\n",
      "----------\n",
      "train Loss: 0.2263 Acc: 0.9119\n",
      "val Loss: 0.0714 Acc: 0.9801\n",
      "\n",
      "Epoch 12/149\n",
      "----------\n",
      "train Loss: 0.1938 Acc: 0.9250\n",
      "val Loss: 0.0724 Acc: 0.9664\n",
      "\n",
      "Epoch 13/149\n",
      "----------\n",
      "train Loss: 0.2029 Acc: 0.9233\n",
      "val Loss: 0.0362 Acc: 0.9870\n",
      "\n",
      "Epoch 14/149\n",
      "----------\n",
      "train Loss: 0.1831 Acc: 0.9279\n",
      "val Loss: 0.0203 Acc: 0.9939\n",
      "\n",
      "Epoch 15/149\n",
      "----------\n",
      "train Loss: 0.1874 Acc: 0.9276\n",
      "val Loss: 0.0396 Acc: 0.9817\n",
      "\n",
      "Epoch 16/149\n",
      "----------\n",
      "train Loss: 0.1667 Acc: 0.9423\n",
      "val Loss: 0.0297 Acc: 0.9885\n",
      "\n",
      "Epoch 17/149\n",
      "----------\n",
      "train Loss: 0.1541 Acc: 0.9404\n",
      "val Loss: 0.0305 Acc: 0.9855\n",
      "\n",
      "Epoch 18/149\n",
      "----------\n",
      "train Loss: 0.1772 Acc: 0.9325\n",
      "val Loss: 0.0578 Acc: 0.9794\n",
      "\n",
      "Epoch 19/149\n",
      "----------\n",
      "train Loss: 0.1544 Acc: 0.9394\n",
      "val Loss: 0.0122 Acc: 0.9954\n",
      "\n",
      "Epoch 20/149\n",
      "----------\n",
      "train Loss: 0.1503 Acc: 0.9387\n",
      "val Loss: 0.0294 Acc: 0.9878\n",
      "\n",
      "Epoch 21/149\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9466\n",
      "val Loss: 0.0109 Acc: 0.9977\n",
      "\n",
      "Epoch 22/149\n",
      "----------\n",
      "train Loss: 0.1620 Acc: 0.9364\n",
      "val Loss: 0.0126 Acc: 0.9946\n",
      "\n",
      "Epoch 23/149\n",
      "----------\n",
      "train Loss: 0.1328 Acc: 0.9450\n",
      "val Loss: 0.0207 Acc: 0.9931\n",
      "\n",
      "Epoch 24/149\n",
      "----------\n",
      "train Loss: 0.1382 Acc: 0.9446\n",
      "val Loss: 0.0175 Acc: 0.9939\n",
      "\n",
      "Epoch 25/149\n",
      "----------\n",
      "train Loss: 0.1369 Acc: 0.9407\n",
      "val Loss: 0.0134 Acc: 0.9985\n",
      "\n",
      "Epoch 26/149\n",
      "----------\n",
      "train Loss: 0.1038 Acc: 0.9594\n",
      "val Loss: 0.0137 Acc: 0.9977\n",
      "\n",
      "Epoch 27/149\n",
      "----------\n",
      "train Loss: 0.1398 Acc: 0.9423\n",
      "val Loss: 0.0117 Acc: 0.9977\n",
      "\n",
      "Epoch 28/149\n",
      "----------\n",
      "train Loss: 0.1174 Acc: 0.9564\n",
      "val Loss: 0.0087 Acc: 0.9985\n",
      "\n",
      "Epoch 29/149\n",
      "----------\n",
      "train Loss: 0.1240 Acc: 0.9512\n",
      "val Loss: 0.0268 Acc: 0.9931\n",
      "\n",
      "Epoch 30/149\n",
      "----------\n",
      "train Loss: 0.1220 Acc: 0.9525\n",
      "val Loss: 0.0101 Acc: 0.9962\n",
      "\n",
      "Epoch 31/149\n",
      "----------\n",
      "train Loss: 0.1153 Acc: 0.9577\n",
      "val Loss: 0.0102 Acc: 0.9954\n",
      "\n",
      "Epoch 32/149\n",
      "----------\n",
      "train Loss: 0.1129 Acc: 0.9584\n",
      "val Loss: 0.0374 Acc: 0.9893\n",
      "\n",
      "Epoch 33/149\n",
      "----------\n",
      "train Loss: 0.1197 Acc: 0.9538\n",
      "val Loss: 0.0189 Acc: 0.9969\n",
      "\n",
      "Epoch 34/149\n",
      "----------\n",
      "train Loss: 0.1067 Acc: 0.9613\n",
      "val Loss: 0.0123 Acc: 0.9977\n",
      "\n",
      "Epoch 35/149\n",
      "----------\n",
      "train Loss: 0.1211 Acc: 0.9505\n",
      "val Loss: 0.0184 Acc: 0.9939\n",
      "\n",
      "====================\n",
      "EARLY STOPPING: Validation loss did not improve for 7 epochs.\n",
      "Stopping at epoch 35.\n",
      "====================\n",
      "\n",
      "Training complete in 38m 14s\n",
      "Best val Acc: 0.998471\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=150)\n",
    "torch.save(model_conv.state_dict(), 'resnet_best_weights_4.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1c04e",
   "metadata": {},
   "source": [
    "the model is as good as it can be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dcb158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
